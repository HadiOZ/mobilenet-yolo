{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 20:34:53.371221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-31 20:34:53.371259: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys  \n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import utillity as utill\n",
    "import yolo_utils\n",
    "import numpy as np\n",
    "import models as mdl\n",
    "from tensorflow.keras import models, layers, activations as act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  'image_size' : (608, 608, 3),\n",
    "  'anchors' : [5, 8, 15, 28, 37, 61, 80, 125, 159, 230],\n",
    "  'stride' : 32,\n",
    "  'xyscale': 1.05,\n",
    "\n",
    "  # Training\n",
    "  'iou_loss_thresh': 0.5,\n",
    "  'batch_size': 8,\n",
    "  'num_gpu': 1,  # 2,\n",
    "\n",
    "  # Inference\n",
    "  'max_boxes': 100,\n",
    "  'iou_threshold': 0.5,\n",
    "  'score_threshold': 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('..','assets', 'model.tflite')\n",
    "weight_path = os.path.join('..', 'assets', 'new2-model-mobilenet-yolo-resume.159-107.74.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tf.lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_model(config, number_class):\n",
    "  #anchors = np.array(config['anchors']).reshape((5, 2))\n",
    "\n",
    "  inputs = layers.Input(config['image_size'])\n",
    "  backbone = mdl.MobileNet(inputs)\n",
    "  head = yolo_utils.yolo_head(backbone.outputs[2], number_of_class=number_class, anchors_size=5)\n",
    "  # head = layers.Reshape((head.shape[1], head.shape[1], anchors.shape[0], 5+number_class))(head)\n",
    "  # # spliter = tf.split(head, (2, 2, 1, number_class), axis=-1)\n",
    "  # pred_xy = act.sigmoid(head[...,:2])\n",
    "  # pred_conf = act.sigmoid(head[...,4:5])\n",
    "  # pred_class = act.sigmoid(head[...,5:])\n",
    "\n",
    "  # grid = np.meshgrid(np.arange(head.shape[1]), np.arange(head.shape[1]))  # (52, 52) (52, 52)\n",
    "  # grid = np.expand_dims(np.stack(grid, axis=-1), axis=2)  # (52, 52, 1, 2)\n",
    "  # grid = np.array(grid).astype('float32')\n",
    "\n",
    "  # pred_xy = ((pred_xy * config['xyscale']) - 0.5 * (config['xyscale'] - 1) + grid) * config['stride']\n",
    "  # pred_wh = act.exponential(head[...,2:4]) * anchors\n",
    "\n",
    "  # box_x1y1 = pred_xy - pred_wh / 2  # (?, 52, 52, 3, 2)\n",
    "  # box_x2y2 = pred_xy + pred_wh / 2\n",
    "  # pred_x1y1x2y2 = np.concatenate((box_x1y1, box_x2y2), axis=-1)\n",
    "\n",
    "  # predict = np.concatenate((pred_x1y1x2y2, pred_conf, pred_class), axis=-1)\n",
    "\n",
    "  # # bs = tf.shape(pred_x1y1x2y2)[0]\n",
    "  # # boxes = tf.zeros((bs, 0, 4))\n",
    "  # # confidence = tf.zeros((bs, 0, 1))\n",
    "  # # class_probabilities = tf.zeros((bs, 0, number_class))\n",
    "\n",
    "  # # boxes = tf.concat([boxes, tf.reshape(pred_x1y1x2y2, (bs, -1, 4))], axis=1)\n",
    "  # # confidence = tf.concat([confidence, tf.reshape(spliter[2], (bs, -1, 1))], axis=1)\n",
    "  # # class_probabilities = tf.concat([class_probabilities, tf.reshape(spliter[3], (bs, -1, number_class))], axis=1)\n",
    "\n",
    "  # # scores = confidence * class_probabilities\n",
    "  # # boxes = tf.expand_dims(boxes, axis=-2)\n",
    "  # # boxes = boxes / config['image_size'][0] \n",
    "\n",
    "  # # result = tf.image.combined_non_max_suppression(\n",
    "  # #       boxes=boxes,  # y1x1, y2x2 [0~1]\n",
    "  # #       scores=scores,\n",
    "  # #       max_output_size_per_class=config['max_boxes'],\n",
    "  # #       max_total_size=config['max_boxes'],  # max_boxes: Maximum nmsed_boxes in a single img.\n",
    "  # #       iou_threshold=config['iou_threshold'],  # iou_threshold: Minimum overlap that counts as a valid detection.\n",
    "  # #       score_threshold=config['score_threshold'],  # # Minimum confidence that counts as a valid detection.\n",
    "  # #   )\n",
    "  # # print(result[0].shape)\n",
    "  # # print(result[1].shape)\n",
    "  # # print(predict.shape)\n",
    "\n",
    " \n",
    "  return models.Model(inputs, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 16:09:11.649818: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-12-15 16:09:11.649877: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ozmonday): /proc/driver/nvidia/version does not exist\n",
      "2021-12-15 16:09:11.650224: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 76, 76, 256)\n",
      "(None, 38, 38, 512)\n",
      "(None, 19, 19, 1024)\n"
     ]
    }
   ],
   "source": [
    "new_model = original_model(config, 1)\n",
    "new_model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 16:09:39.089705: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxn3wljat/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 16:09:47.929982: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2021-12-15 16:09:47.930255: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2021-12-15 16:09:47.973143: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.611ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
      "\n",
      "2021-12-15 16:09:49.010221: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2021-12-15 16:09:49.010299: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2021-12-15 16:09:49.064098: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(new_model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../assets/model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='../assets/model1.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 52 52 18]\n",
      "[ 1 26 26 18]\n",
      "[ 1 13 13 18]\n"
     ]
    }
   ],
   "source": [
    "print(output_details[0]['shape'])\n",
    "print(output_details[1]['shape'])\n",
    "print(output_details[2]['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 20:33:35.279771: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-12-05 20:33:35.279817: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ozmonday): /proc/driver/nvidia/version does not exist\n",
      "2021-12-05 20:33:35.280142: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 416, 416, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_ori = utill.open_image('../test_img/53_Raid_policeraid_53_189.jpg')\n",
    "img = tf.image.resize(img_ori, (input_details[0]['shape'][1], input_details[0]['shape'][1]))\n",
    "img = img / 255\n",
    "img_exp = np.expand_dims(img, axis=0)\n",
    "img_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nms iou: 0.413 score: 0.3\n",
      "# of bboxes: 1\n"
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], img_exp)\n",
    "interpreter.invoke()\n",
    "\n",
    "anchors = np.array(config['anchors']).reshape((3, 3, 2))\n",
    "large_output = interpreter.get_tensor(output_details[0]['index'])\n",
    "medium_output = interpreter.get_tensor(output_details[1]['index'])\n",
    "small_output = interpreter.get_tensor(output_details[2]['index'])\n",
    "outputs = [large_output, medium_output, small_output]\n",
    "outputs = yolo_utils.yolo_detector(outputs, anchors, 1, config['strides'], config['xyscale'])\n",
    "outputs = utill.nms(outputs, config['image_size'], 1, config['iou_threshold'], config['score_threshold'])\n",
    "# output_data = yolo_utils.get_boxes(output_data, anchors, 1, config['stride'], config['xyscale'])\n",
    "# output_data = utill.nms(output_data, config['image_size'], 1, config['iou_threshold'], config['score_threshold'])\n",
    "boxes = utill.get_detection_data(outputs, img_ori.shape)\n",
    "#utill.plot_bbox(img_ori, boxes, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "inputs = layers.Input()\n",
    "resize = tf.image.resize(inputs, (30, 30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 59, 59, 5, 4)\n",
      "[[11 10  9  8  7  6]\n",
      " [ 5  4  3  2  1  0]]\n"
     ]
    }
   ],
   "source": [
    "randoms = np.random.rand(12, 59, 59 ,5, 6)\n",
    "randoms.shape\n",
    "\n",
    "spliter = tf.split(randoms, (2,2,1,1), axis=-1)\n",
    "\n",
    "spliter[0] = tf.sigmoid(spliter[0])\n",
    "spliter[2] = tf.sigmoid(spliter[2])\n",
    "spliter[3] = tf.sigmoid(spliter[3])\n",
    "pred_xywh = tf.concat((spliter[0], spliter[1]), axis=-1)\n",
    "print(pred_xywh.shape)\n",
    "\n",
    "rang = np.arange(12)\n",
    "rang = -np.sort(-rang).reshape(2,6)\n",
    "print(rang)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
