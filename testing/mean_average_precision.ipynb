{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 15:15:19.611105: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-07 15:15:19.611144: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys  \n",
    "sys.path.insert(0, '..')\n",
    "import numpy as np\n",
    "import platform\n",
    "import mobilenetyolo as model\n",
    "import utillity as utill\n",
    "import models\n",
    "import yolo_utils\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers, models as mdl, backend as k\n",
    "from mobilenetyolo import MNetYolo\n",
    "from matplotlib import image, pyplot as plt, patches as patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = os.path.join('..', 'assets', 'mobilenet-yolo-light.01-1222.80.h5')\n",
    "val_notation = os.path.join('..', 'assets', 'validation.txt')\n",
    "train_notation = os.path.join('..', 'assets', 'training.txt')\n",
    "predict_path = os.path.join('..', 'assets', 'mnet_yolo', 'predict')\n",
    "gt_path = os.path.join('..', 'assets', 'mnet_yolo', 'ground_truth')\n",
    "output_ap = os.path.join('..', 'assets', 'mnet_yolo', 'result')\n",
    "temp_json = os.path.join('..', 'assets', 'mnet_yolo','temp_json') \n",
    "class_name = os.path.join('..', 'assets', 'class_name.txt')\n",
    "image_path = os.path.join('/home', 'hadioz', 'Documents', 'skripsi', 'dataset', 'WIDER_val', 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = { \n",
    "  'image_size' : (416, 416, 3),\n",
    "  'anchors' : [ 3, 5, 7, 12, 12, 22, 19, 33, 26, 51, 52, 47, 39, 76, 54, 111, 98, 94, 79, 163, 157, 153, 113, 236, 224, 222, 183, 338 ],\n",
    "  'strides' : [ 16, 32 ],\n",
    "  'xyscale':[ 0.1, 0.05 ],\n",
    "  'detector_count' : 2,\n",
    "  'anchor_size_perdetector': 7,\n",
    "\n",
    "  # Training\n",
    "  'iou_loss_thresh': 0.5,\n",
    "  'batch_size': 32,\n",
    "  'num_gpu': 1,  # 2,\n",
    "\n",
    "  # Inference\n",
    "  'max_boxes': 100,\n",
    "  'iou_threshold': 0.5,\n",
    "  'score_threshold': 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(val_notation) as file:\n",
    "  data = json.load(file)\n",
    "\n",
    "easy =[obj for obj in data if int(obj['name'].split('--')[0]) <= 20]\n",
    "medium = [obj for obj in data if int(obj['name'].split('--')[0]) <= 40 and int(obj['name'].split('--')[0]) > 20]\n",
    "hard = [obj for obj in data if int(obj['name'].split('--')[0]) > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolo = MNetYolo(config, class_name, weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolo.eval_map(gt_path, predict_path, temp_json, output_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[3]['name'])\n",
    "test_image = os.path.join(image_path, data[69]['name'])\n",
    "model_yolo.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolo.export_predict(hard, image_path, predict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolo.export_gt(hard, image_path, gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_notation(img, boxs):\n",
    "    \n",
    "    high = img.shape[0]\n",
    "    wide = img.shape[1]\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for label in boxs:\n",
    "        x = round(label['data'][0] * wide)\n",
    "        y = round(label['data'][1] * high)\n",
    "        w = round(label['data'][2] * wide)\n",
    "        h = round(label['data'][3] * high)\n",
    "        result.append({ 'index' : label['index'], 'data' : [x, y, w, h]})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(image, boxs):\n",
    "    fig, ax = plt.subplots(figsize = (15,15))\n",
    "    ax.imshow(image, interpolation='nearest')\n",
    "    boxs = decode_notation(image, boxs)\n",
    "    print(boxs)\n",
    "    for box in boxs:\n",
    "        x1y1 = patches.Circle((int(box['data'][0]), int(box['data'][1])), radius=5, color='blue')\n",
    "        x2y2 = patches.Circle((int(box['data'][0] + box['data'][2]), int(box['data'][1] + box['data'][3])), radius=5, color='green')\n",
    "        cpoint = patches.Circle((int(box['data'][0] + (box['data'][2]/2)), int(box['data'][1] + (box['data'][3]/2))), radius=5, color='yellow')\n",
    "        rect = patches.Rectangle((int(box['data'][0]), int(box['data'][1])), int(box['data'][2]), int(box['data'][3]), linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.add_patch(x1y1)\n",
    "        ax.add_patch(cpoint)                            \n",
    "        ax.add_patch(x2y2)\n",
    "\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = utill.open_image( os.path.join(image_path, data[60]['name']), True)\n",
    "draw_bbox(img, data[60]['objects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 15:15:42.368278: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-07 15:15:42.368402: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ozmonday): /proc/driver/nvidia/version does not exist\n",
      "2022-01-07 15:15:42.368951: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 26, 26, 512) dtype=float32 (created by layer 'conv_pw_11_relu')>, <KerasTensor: shape=(None, 13, 13, 1024) dtype=float32 (created by layer 'conv_pw_13_relu')>]\n"
     ]
    }
   ],
   "source": [
    "def build_model(config, weight_path, load_pretrained=False):\n",
    "  anchors = np.array(config['anchors']).reshape((2, 7, 2))\n",
    "  \n",
    "  inputs = layers.Input(config['image_size'])\n",
    "  backbone = models.MobileNet(inputs)\n",
    "  print(backbone.outputs)\n",
    "  yolo_head = models.FPN_light(backbone, 1, 7)\n",
    "  basic_model = mdl.Model(inputs, yolo_head)\n",
    "\n",
    "  if load_pretrained:\n",
    "    basic_model.load_weights(weight_path)\n",
    "\n",
    "  model_output = yolo_utils.yolo_detector_light(\n",
    "            basic_model.outputs, anchors, 1, config['strides'], config['xyscale'])\n",
    "  nms = utill.nms(model_output, config['image_size'], 1, config['iou_threshold'], config['score_threshold'])\n",
    "  \n",
    "  return mdl.Model(basic_model.input, nms)\n",
    "  \n",
    "\n",
    "inf_model = build_model(config, weight_path, True)\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_image(config, img):\n",
    "  img = img /255\n",
    "  img = cv2.resize(img, config['image_size'][:2])\n",
    "  return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]2022-01-07 15:16:00.620862: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "filenames = [line['name'] for line in data[:10]]\n",
    "img_path = [os.path.join(image_path, line) for line in filenames]\n",
    "cname = [line.strip() for line in open(class_name).readlines()]\n",
    "\n",
    "resume = []\n",
    "\n",
    "for idx in tqdm(range(0, len(img_path), 2)):\n",
    "  paths = img_path[idx:idx+2]\n",
    "  imgs = np.zeros((len(paths), *config['image_size']))\n",
    "  raw_img_shapes = []\n",
    "\n",
    "  for i, path in enumerate(paths):\n",
    "    img = utill.open_image(path, False)\n",
    "    raw_img_shapes.append(img.shape)\n",
    "    img = preprocessing_image(config, img)\n",
    "    imgs[i] = img\n",
    "\n",
    "  b_boxes, b_scores, b_classes, b_valid_detections = inf_model.predict(imgs)\n",
    "  print(b_boxes)\n",
    "\n",
    "  for k in range(len(paths)):\n",
    "    num_boxes = b_valid_detections[k]\n",
    "    raw_img_shape = raw_img_shapes[k]\n",
    "    boxes = b_boxes[k, :num_boxes]\n",
    "    classes = b_classes[k, :num_boxes]\n",
    "    scores = b_scores[k, :num_boxes]\n",
    "  \n",
    "    boxes[:, [0, 2]] = (boxes[:, [0, 2]] * raw_img_shape[1])  # w\n",
    "    boxes[:, [1, 3]] = (boxes[:, [1, 3]] * raw_img_shape[0])  # h\n",
    "    cls_names = [cname[int(c)] for c in classes]\n",
    "\n",
    "    ipath = paths[k]\n",
    "    filename = ipath.split(os.sep)[-1].split('.')[0]\n",
    "\n",
    "    objects = []\n",
    "\n",
    "    output_path = os.path.join(predict_path, filename+'.txt')\n",
    "    with open(output_path, 'w') as pred_file:\n",
    "      for box_idx in range(num_boxes):\n",
    "        b = boxes[box_idx]\n",
    "        pred_file.write(f'{cls_names[box_idx]} {scores[box_idx]} {b[0]} {b[1]} {b[2]} {b[3]}\\n')\n",
    "        objects.append({\"index\" : 1+box_idx, \"score\": scores[box_idx], \"data\" : [float(b[0]), float(b[1]), float(b[2]), float(b[3])]})\n",
    "    resume.append({\"name\": filename, \"objects\" : objects})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = os.path.join('..', 'assets', 'ground_truth')\n",
    "\n",
    "for img in data[:10]:\n",
    "  fn = os.path.join(image_path, img['name'])\n",
    "  im = utill.open_image(fn)\n",
    "  fn = fn.split(os.sep)[-1].split('.')[0]\n",
    "  output_path = os.path.join(gt_path, fn+'.txt')\n",
    "  print(output_path)\n",
    "  with open(output_path, 'w') as gt_file:\n",
    "    for object in img['objects']:\n",
    "      x1 = object['data'][0] * im.shape[0]\n",
    "      y1 = object['data'][1] * im.shape[1]\n",
    "      x2 = x1 + (object['data'][2] * im.shape[0])\n",
    "      y2 = y1 + (object['data'][3] * im.shape[1])\n",
    "      print('face {} {} {} {}'.format(x1,y1, x2, y2))\n",
    "      gt_file.write(f'face {x1} {y1} {x2} {y2}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "gt_counter_per_class = {}\n",
    "counter_images_per_class = {}\n",
    "gt_files = []\n",
    "\n",
    "filename_list = glob(gt_path + '/*.txt')\n",
    "assert len(filename_list) > 0, 'no ground truth file'\n",
    "filename_list.sort()\n",
    "\n",
    "for title in filename_list:\n",
    "  file_id = title.split(\".txt\", 1)[0] # ../assets/ground_truth/0_Parade_Parade_0_120\n",
    "  file_id = os.path.basename(os.path.normpath(file_id)) # 0_Parade_Parade_0_120\n",
    "  temp_path = os.path.join(predict_path, (file_id + \".txt\"))\n",
    "  assert os.path.exists(temp_path), \"Error. File not found: {}\\n\".format(temp_path)\n",
    "  lines_list = utill.read_txt_to_list(title)\n",
    "  \n",
    "  bounding_boxes = []\n",
    "  already_seen_classes = []\n",
    "  for line in lines_list:\n",
    "    class_name, left, top, right, bottom = line.split()\n",
    "    bbox = left + \" \" + top + \" \" + right + \" \" + bottom\n",
    "    bounding_boxes.append({\"class_name\": class_name, \"bbox\": bbox, \"used\": False})\n",
    "    \n",
    "    # count that object\n",
    "    if class_name in gt_counter_per_class:\n",
    "      gt_counter_per_class[class_name] += 1\n",
    "    else:\n",
    "      # if class didn't exist yet\n",
    "      gt_counter_per_class[class_name] = 1\n",
    "\n",
    "    if class_name not in already_seen_classes:\n",
    "      if class_name in counter_images_per_class:\n",
    "        counter_images_per_class[class_name] += 1\n",
    "      else:\n",
    "        # if class didn't exist yet\n",
    "        counter_images_per_class[class_name] = 1\n",
    "      already_seen_classes.append(class_name)\n",
    "\n",
    "  new_temp_file = os.path.join(temp_json, file_id+\"_ground_truth.json\") #TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\"\n",
    "  gt_files.append(new_temp_file)\n",
    "  with open(new_temp_file, 'w') as outfile:\n",
    "    json.dump(bounding_boxes, outfile)\n",
    "\n",
    "gt_classes = list(gt_counter_per_class.keys())\n",
    "# let's sort the classes alphabetically\n",
    "gt_classes = sorted(gt_classes)\n",
    "n_classes = len(gt_classes)\n",
    "print(gt_classes, gt_counter_per_class)\n",
    "\n",
    "dr_files_list = sorted(glob(os.path.join(predict_path, '*.txt')))\n",
    "# print(dr_files_list)\n",
    "\n",
    "for class_index, class_name in enumerate(gt_classes):\n",
    "  bounding_boxes = []\n",
    "  for txt_file in dr_files_list:\n",
    "    file_id = txt_file.split(\".txt\", 1)[0]\n",
    "    file_id = os.path.basename(os.path.normpath(file_id))\n",
    "    temp_path = os.path.join(gt_path, (file_id + \".txt\"))\n",
    "    if class_index == 0 :\n",
    "      if not os.path.exists(temp_path):\n",
    "        error_msg = f\"Error. File not found: {temp_path}\\n\"\n",
    "        print(error_msg)\n",
    "\n",
    "    lines = utill.read_txt_to_list(txt_file)\n",
    "    for line in lines:\n",
    "      try:\n",
    "        tmp_class_name, confidence, left, top, right, bottom = line.split()\n",
    "      except ValueError:\n",
    "        error_msg = f\"\"\"Error: File {txt_file} in the wrong format.\\n \n",
    "                        Expected: <class_name> <confidence> <left> <top> <right> <bottom>\\n \n",
    "                        Received: {line} \\n\"\"\"\n",
    "        print(error_msg)\n",
    "      if tmp_class_name == class_name:\n",
    "        bbox = left + \" \" + top + \" \" + right + \" \" + bottom\n",
    "        bounding_boxes.append({\"confidence\": confidence, \"file_id\": file_id, \"bbox\": bbox})\n",
    "\n",
    "  bounding_boxes.sort(key=lambda x: float(x['confidence']), reverse=True)\n",
    "\n",
    "  with open(temp_json + \"/\" + class_name + \"_dr.json\", 'w') as outfile:\n",
    "    json.dump(bounding_boxes, outfile)\n",
    "\n",
    "sum_AP = 0.0\n",
    "ap_dictionary = {}\n",
    "\n",
    "with open(output_ap + \"/output.txt\", 'w') as output_file:\n",
    "  output_file.write(\"# AP and precision/recall per class\\n\")\n",
    "  count_true_positives = {}\n",
    "  \n",
    "  for class_index, class_name in enumerate(gt_classes):\n",
    "\n",
    "    count_true_positives[class_name] = 0\n",
    "\n",
    "    dr_file = os.path.join(temp_json, class_name + \"_dr.json\")\n",
    "    # print(dr_file)\n",
    "    dr_data = json.load(open(dr_file))\n",
    "    # print(len(dr_data))\n",
    "\n",
    "    nd = len(dr_data)\n",
    "    tp = [0] * nd\n",
    "    # print(len(tp))\n",
    "    fp = [0] * nd\n",
    "  \n",
    "    for idx, detection in enumerate(dr_data):\n",
    "      file_id = detection[\"file_id\"]\n",
    "      # print(f'filename : {file_id}')\n",
    "      gt_file = os.path.join(temp_json, file_id + \"_ground_truth.json\")\n",
    "      # print(gt_file)\n",
    "      ground_truth_data = json.load(open(gt_file))\n",
    "      # print(len(ground_truth_data))\n",
    "      ovmax = -1\n",
    "      gt_match = -1\n",
    "\n",
    "      bb = [float(x) for x in detection[\"bbox\"].split()]\n",
    "      # print(f'bonding_box prediction: {bb}')\n",
    "\n",
    "      for obj in ground_truth_data:\n",
    "        if obj[\"class_name\"] == class_name:\n",
    "          bbgt = [float(x) for x in obj[\"bbox\"].split()]\n",
    "          bi = [max(bb[0], bbgt[0]), max(bb[1], bbgt[1]), min(bb[2], bbgt[2]), min(bb[3], bbgt[3])]\n",
    "          # print(f'bi : {bi}')\n",
    "          iw = bi[2] - bi[0] \n",
    "          ih = bi[3] - bi[1]\n",
    "          # print(iw)\n",
    "          # print(ih)\n",
    "\n",
    "          if iw > 0 and ih > 0:\n",
    "            # compute overlap (IoU) = area of intersection / area of union\n",
    "            ua = ((bb[2] - bb[0]) * (bb[3] - bb[1])) + ((bbgt[2] - bbgt[0]) * (bbgt[3] - bbgt[1])) - (iw * ih)\n",
    "            ov = (iw * ih) / ua\n",
    "            # print(f'ov : {ov}')\n",
    "            if ov > ovmax:\n",
    "              ovmax = ov\n",
    "              gt_match = obj\n",
    "      \n",
    "      # print(f'gt_match : {gt_match}')\n",
    "      # print(f'ovmax : {ovmax} \\n')\n",
    "      \n",
    "      min_overlap = 0.05\n",
    "      if ovmax >= min_overlap:\n",
    "        if not bool(gt_match[\"used\"]):\n",
    "          # true positive\n",
    "          tp[idx] = 1\n",
    "          gt_match[\"used\"] = True\n",
    "          count_true_positives[class_name] += 1\n",
    "          # update the \".json\" file\n",
    "          with open(gt_file, 'w') as f:\n",
    "            f.write(json.dumps(ground_truth_data))\n",
    "        else:\n",
    "          # false positive (multiple detection)\n",
    "          fp[idx] = 1\n",
    "      else:\n",
    "        fp[idx] = 1\n",
    "\n",
    "    cumsum = 0\n",
    "    for idx, val in enumerate(fp):\n",
    "      fp[idx] += cumsum\n",
    "      cumsum += val\n",
    "    print('fp ', cumsum)\n",
    "    cumsum = 0\n",
    "    for idx, val in enumerate(tp):\n",
    "      tp[idx] += cumsum\n",
    "      cumsum += val\n",
    "    print('tp ', cumsum)\n",
    "    rec = tp[:]\n",
    "    for idx, val in enumerate(tp):\n",
    "      rec[idx] = float(tp[idx]) / gt_counter_per_class[class_name]\n",
    "    print('recall ', cumsum)\n",
    "    prec = tp[:]\n",
    "    for idx, val in enumerate(tp):\n",
    "      prec[idx] = float(tp[idx]) / (fp[idx] + tp[idx])\n",
    "    print('prec ', cumsum)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    # print(temp_path)\n",
    "    # print(file_id)\n",
    "\n",
    "#   print(already_seen_classes)\n",
    "# print(gt_counter_per_class)\n",
    "# print(counter_images_per_class)\n",
    "    \n",
    "\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
